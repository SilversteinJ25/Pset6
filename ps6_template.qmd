---
title: "Problem Set 6 - Waze Shiny Dashboard"
author: "Justine Silverstein"
date: idk, due date
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
1. **ps6:** Due Sat 23rd at 5:00PM Central. Worth 100 points (80 points from questions, 10 points for correct submission and 10 points for code style) + 10 extra credit. 

We use (`*`) to indicate a problem that we think might be time consuming. 

# Steps to submit (10 points on PS6) {-}

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: \*\*\_\_\*\*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  \*\*\_\_\*\* (2 point)
3. Late coins used this pset: 1  Late coins left after submission: 0

4. Before starting the problem set, make sure to read and agree to the terms of data usage for the Waze data [here](https://canvas.uchicago.edu/courses/59054/quizzes/130617).

5. Knit your `ps6.qmd` as a pdf document and name it `ps6.pdf`.
6. Submit your `ps6.qmd`, `ps6.pdf`, `requirements.txt`, and all created folders (we will create three Shiny apps so you will have at least three additional folders) to the gradescope repo assignment (5 points).
7. Submit `ps6.pdf` and also link your Github repo via Gradescope (5 points)
8. Tag your submission in Gradescope. For the Code Style part (10 points) please tag the whole correspondingsection for the code style rubric.

*Notes: see the [Quarto documentation (link)](https://quarto.org/docs/authoring/figures.html) for directions on inserting images into your knitted document.*

*IMPORTANT: For the App portion of the PS, in case you can not arrive to the expected functional dashboard we will need to take a look at your `app.py` file. You can use the following code chunk template to "import" and print the content of that file. Please, don't forget to also tag the corresponding code chunk as part of your submission!*

```{python}
#| echo: true
#| eval: false

#I did not use the below code chunk, it was unnecessary

file_path ='/Users/justinesilverstein/Desktop/Pset6/basic-app'

def print_file_contents(file_path):
    """Print contents of a file."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
            print("```python")
            print(content)
            print("```")
    except FileNotFoundError:
        print("```python")
        print(f"Error: File '{file_path}' not found")
        print("```")
    except Exception as e:
        print("```python") 
        print(f"Error reading file: {e}")
        print("```")

print_file_contents("./top_alerts_map_byhour/app.py") # Change accordingly
```

```{python} 
#| echo: false

# Import required packages.
import pandas as pd
import altair as alt 
import pandas as pd
from datetime import date
import numpy as np
alt.data_transformers.disable_max_rows() 
from shiny import App, render, ui

import json
```

# Background {-}

## Data Download and Exploration (20 points){-} 

1. Using the zipfile package, unzip the waze_data.zip file. You will find two files in the unzipped folder: waze_data.csv (the whole dataset) and waze_data_sample.csv (a sample of 1% of the data). Load the waze_data_sample.csv file into a pandas DataFrame. What are the variable names and what are their data types? When reporting data types, report using the Altair syntax (e.g., Quantitative, Nominal, etc.). When reporting data types, ignore the columns ts, geo, and geoWKT.

Using Altair syntax, all the variables are either Quantitative or Nominal. The Nominal variables are city, street, uuid, country, type, and subtype. The Quantitative variabless are confidence, nThumbsUp, roadType, reliability, magvar, and reportRating.

```{python}
path = "/Users/justinesilverstein/Desktop/Pset6"
waze_data = pd.read_csv('waze_data_sample.csv')
excluded_columns = ['ts', 'geo', 'geoWKT']
filtered_waze_data = waze_data.drop(columns=excluded_columns)

for column, dtype in filtered_data.dtypes.items():
    if dtype == 'object':
        print(f"{column}: Nominal")
    elif dtype == 'int64' or dtype == 'float64':
        print(f"{column}: Quantitative")
    elif dtype == 'datetime64[ns]':
        print(f"{column}: Temporal")
    else:
        print(f"{column}: Unknown")
```

2. Now load the waze_data.csv file into a pandas DataFrame. With this file, Create a stacked bar chart where the x-axis is each variable and the stacked bar has two categories: the number of observations where that variable is NULL or missing, and the number of observations where they are not. Which variables have the NULL values? Which variable has the highest share of observations that are missing?

The variables nThumbsUp, street, and subtype all have misisng observations with nThumbsUp having the most missing observations.

```{python}
path = "/Users/justinesilverstein/Desktop/Pset6"
full_waze_data = pd.read_csv('waze_data.csv')

df_counts = pd.DataFrame({
    'variable': full_waze_data.columns,  
    'NULL': full_waze_data.isnull().sum().values,    
    'Non-NULL': full_waze_data.notnull().sum().values 
})

df_counts_long = df_counts.melt(id_vars='variable', value_vars=['NULL', 'Non-NULL'], var_name='status', value_name='count')

chart = alt.Chart(df_counts_long).mark_bar().encode(
    x='variable:N',  
    y='count:Q',  
    color='status:N',  
    tooltip=['variable:N', 'status:N', 'count:Q']  
).properties(
    title='Count of NULL values per variable'
)

chart.show()
```

3. Take a look at the variables type and subtype. Even though they are informative, some are not aesthetically pleasing, and others are diﬀicult to read. Before going into the development of our Shiny Apps, we will create a crosswalk table to help us have cleaner
data.

Print the unique values for the columns type and subtype. How many types have a subtype that is NA? Even though we print the combinations for two columns, can you identify which type has subtypes that have enough information to consider that they could have sub-subtypes? 

Write out a bulleted listed with the values at each layer given this hierarchy. For this list, use names that are clean and readable. For example, using ACCIDENT_MAJOR in the dashboard is not as readable or user-friendly as one menu option that says Accident and then a subsequent one that says Major. 

Finally, do you consider that we should keep the NA subtypes? Why? If you choose to keep the NA subtypes, code them as “Unclassified.”


```{python}

print("Unique values for 'type':")
print(full_waze_data['type'].unique())

print("\nUnique values for 'subtype':")
print(full_waze_data['subtype'].unique())

na_subtypes = full_waze_data[full_waze_data['subtype'].isna()]['type'].value_counts()
print("\nTypes with NA subtypes:")
print(na_subtypes)

type_subtype_combinations = full_waze_data.groupby(['type', 'subtype']).size().reset_index(name='count')
print("\nType-Subtype Combinations and their counts:")
print(type_subtype_combinations)
```

4. Print the unique values for the columns type and subtype. How many types have a subtype that is NA? Even though we print the combinations for two columns, can you identify which type has subtypes that have enough information to consider that they could have sub-subtypes? Write out a bulleted listed with the values at each layer given this hierarchy. For this list, use names that are clean and readable. For example, using ACCIDENT_MAJOR in the dashboard is not as readable or user-friendly as one menu option that says Accident and then a subsequent one that says Major. Finally, do you consider that we should keep the NA subtypes? Why? If you choose to keep the NA subtypes, code them as “Unclassified.”






We want to assign this newly created hierarchy to the original data. To do so, we will
create the crosswalk DataFrame and then merge it with the rest of the data.


1. To create a crosswalk, define a pandas DataFrame which has five columns: type and subtype from the original dataset, and three new columns updated_type, updated_subtype, and updated_subsubtype.
```{python}

```

2. Let each row of this DataFrame be a unique combination of type and subtype. Then, based on the hierarchy you proposed in Q3, fill in updated_type, updated_subtype, and updated_subsubtype accordingly. Remember to name the NA subtypes as “Unclassified”. Hint: your crosswalk should have 32 observations.

```{python}

```

3. Merge the crosswalk with the original data using type and subtype. How many rows are there for Accident - Unclassified?

```{python}

```

4. EXTRA CREDIT/OPTIONAL: After merging the crosswalk,can you check that the crosswalk and the new merged dataset have the same values in type and subtype?

```{python}

```


# App #1: Top Location by Alert Type Dashboard (30 points){-}

1. 

a. 
```{python}

```

b. 
```{python}

```


c. 
```{python}

```

d. 
```{python}

```

3. 
    
a. 

```{python}

```
    

b. 
```{python}
# MODIFY ACCORDINGLY
file_path = "./top_alerts_map/chicago-boundaries.geojson"
#----

with open(file_path) as f:
    chicago_geojson = json.load(f)

geo_data = alt.Data(values=chicago_geojson["features"])

```

4. 

```{python}

```

5. 

a. 

```{python}

```

b. 
```{python}

```

c. 
```{python}

```

d. 
```{python}

```

e. 

# App #2: Top Location by Alert Type and Hour Dashboard (20 points) {-}

1. 

a. 


    
b. 
```{python}

```

c.

```{python}

```
    

2.

a. 



b. 


c. 


# App #3: Top Location by Alert Type and Hour Dashboard (20 points){-}

1. 


a. 

b. 

```{python}

```

2. 

a. 


b. 
    
3. 

a. 
    

b. 


c. 


d.
