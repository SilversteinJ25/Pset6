---
title: "Problem Set 6 - Waze Shiny Dashboard"
author: "Justine Silverstein"
date: November 23, 2024
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
1. **ps6:** Due Sat 23rd at 5:00PM Central. Worth 100 points (80 points from questions, 10 points for correct submission and 10 points for code style) + 10 extra credit. 

We use (`*`) to indicate a problem that we think might be time consuming. 

# Steps to submit (10 points on PS6) {-}

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: \*\*\_\_\*\*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  \*\*\_\_\*\* (2 point)
3. Late coins used this pset: 1  Late coins left after submission: 0

4. Before starting the problem set, make sure to read and agree to the terms of data usage for the Waze data [here](https://canvas.uchicago.edu/courses/59054/quizzes/130617).

5. Knit your `ps6.qmd` as a pdf document and name it `ps6.pdf`.
6. Submit your `ps6.qmd`, `ps6.pdf`, `requirements.txt`, and all created folders (we will create three Shiny apps so you will have at least three additional folders) to the gradescope repo assignment (5 points).
7. Submit `ps6.pdf` and also link your Github repo via Gradescope (5 points)
8. Tag your submission in Gradescope. For the Code Style part (10 points) please tag the whole correspondingsection for the code style rubric.

*Notes: see the [Quarto documentation (link)](https://quarto.org/docs/authoring/figures.html) for directions on inserting images into your knitted document.*

```{python} 
#| echo: false

# Import required packages.
import pandas as pd
import altair as alt 
import pandas as pd
from datetime import date
import numpy as np
alt.data_transformers.disable_max_rows() 
from shiny import App, render, ui
import re 

import json
```

# Background {-}

## Data Download and Exploration (20 points){-} 

1. Using the zipfile package, unzip the waze_data.zip file. You will find two files in the unzipped folder: waze_data.csv (the whole dataset) and waze_data_sample.csv (a sample of 1% of the data). Load the waze_data_sample.csv file into a pandas DataFrame. What are the variable names and what are their data types? When reporting data types, report using the Altair syntax (e.g., Quantitative, Nominal, etc.). When reporting data types, ignore the columns ts, geo, and geoWKT.

Using Altair syntax, all the variables are either Quantitative or Nominal. The Nominal variables are city, street, uuid, country, type, and subtype. The Quantitative variabless are confidence, nThumbsUp, roadType, reliability, magvar, and reportRating.

```{python}
path = "/Users/justinesilverstein/Desktop/Pset6"
waze_data = pd.read_csv('waze_data_sample.csv')
excluded_columns = ['ts', 'geo', 'geoWKT']
filtered_waze_data = waze_data.drop(columns=excluded_columns)

for column, dtype in filtered_waze_data.dtypes.items():
    if dtype == 'object':
        print(f"{column}: Nominal")
    elif dtype == 'int64' or dtype == 'float64':
        print(f"{column}: Quantitative")
    elif dtype == 'datetime64[ns]':
        print(f"{column}: Temporal")
    else:
        print(f"{column}: Unknown")
```

2. Now load the waze_data.csv file into a pandas DataFrame. With this file, Create a stacked bar chart where the x-axis is each variable and the stacked bar has two categories: the number of observations where that variable is NULL or missing, and the number of observations where they are not. Which variables have the NULL values? Which variable has the highest share of observations that are missing?

The variables nThumbsUp, street, and subtype all have misisng observations with nThumbsUp having the most missing observations.

```{python}
path = "/Users/justinesilverstein/Desktop/Pset6"
full_waze_data = pd.read_csv('waze_data.csv')

df_counts = pd.DataFrame({
    'variable': full_waze_data.columns,  
    'NULL': full_waze_data.isnull().sum().values,    
    'Non-NULL': full_waze_data.notnull().sum().values 
})

df_counts_long = df_counts.melt(id_vars='variable', value_vars=['NULL', 'Non-NULL'], var_name='status', value_name='count')

chart = alt.Chart(df_counts_long).mark_bar().encode(
    x='variable:N',  
    y='count:Q',  
    color='status:N',  
    tooltip=['variable:N', 'status:N', 'count:Q']  
).properties(
    title='Count of NULL values per variable'
)

chart.show()
```

3. Take a look at the variables type and subtype. Even though they informative, some are not aesthetically pleasing, and others are diﬀicult to read. Before going into the development of our Shiny Apps, we will create a crosswalk table to help us have cleaner data.

a. Print the unique values for the columns type and subtype. How many types have a subtype that is NA? Even though we print the combinations for two columns, can you identify which type has subtypes that have enough information to consider that they could have sub-subtypes?

Four types have a subtype with NAs. The subtypes can be seen in the below code's output. Of the four types, Hazard has 19 subtypes, while the others all have less than 5, so it is worth giving it subtypes.

```{python}
print("Unique Types:", full_waze_data['type'].unique())
print("Unique Subtypes:", full_waze_data['subtype'].unique())

na_counts = full_waze_data[full_waze_data['subtype'].isna()].groupby('type').size().reset_index(name='NA Count')

types_with_na = na_counts[na_counts['NA Count'] > 0]
print(f"Number of types with at least one NA subtype: {len(types_with_na)}")

print(full_waze_data.groupby('type')['subtype'].nunique().reset_index(name='Subtype Count'))
```

b. Write out a bulleted listed with the values at each layer given this hierarchy. For this list, use names that are clean and readable. For example, using ACCIDENT_MAJOR in the dashboard is not as readable or user-friendly as one menu option that says Accident and then a subsequent one that says Major.

```{python}
def clean_subtypes(row):
    type_prefix = row['type'] + '_'
    subtype = row['subtype']
    if pd.isna(subtype):
        return 'UNCLASSIFIED'
    if subtype.startswith(type_prefix):
        cleaned_subtype = subtype[len(type_prefix):]  
        cleaned_subtype = cleaned_subtype.replace('_', ' ')  
        return cleaned_subtype
    return subtype

clean_crosswalk = full_waze_data.groupby('type')['subtype'].unique().reset_index()

for _, row in clean_crosswalk.iterrows():
    print(f"{row['type']}:")
    for subtype in row['subtype']:
        cleaned_subtype = clean_subtypes({'type': row['type'], 'subtype': subtype})
        print(f"  - {cleaned_subtype}")
```

c. Finally, do you consider that we should keep the NA subtypes Why? If you choose to keep the NA subtypes, code them as “Unclassified.”

We should keep the NA subtypes. In real life, events can happen that are not easily classified into premade categories. Or we have labeling issues from person to person on how to categorize things, so subtype is left blank. It is a good idea to have an unclassified subtype in such cases. The subtype UNCLASSIFIED has been included in the function in the above code chunk.

4. We want to assign this newly created hierarchy to the original data. To do so, we will create the crosswalk DataFrame and then merge it with the rest of the data.

a. To create a crosswalk, define a pandas DataFrame which has five columns: type and subtype from the original dataset, and three new columns updated_type, updated_subtype, and updated_subsubtype.

```{python}
crosswalk = pd.DataFrame(columns=['type', 'subtype', 'updated_type', 'updated_subtype', 'updated_subsubtype'])
print(crosswalk)
```

b. Let each row of this DataFrame be a unique combination of type and subtype. Then, based on the hierarchy you proposed in Q3, fill in updated_type, updated_subtype, and updated_subsubtype accordingly. Remember to name the NA subtypes as “Unclassified”. Hint: your crosswalk should have 32 observations.

```{python}
clean_crosswalk = full_waze_data.groupby('type')['subtype'].unique().reset_index()

exploded_rows = []
for _, row in clean_crosswalk.iterrows():
    type_value = row['type']
    subtypes = row['subtype']
    for subtype in subtypes:
        cleaned_subtype = clean_subtypes({'type': type_value, 'subtype': subtype})
        exploded_rows.append({
            'type': type_value,
            'subtype': subtype,
            'updated_subtype': cleaned_subtype
        })

crosswalk = pd.DataFrame(exploded_rows)
crosswalk['updated_type'] = crosswalk['type']
crosswalk['subtype'] = crosswalk['subtype'].fillna('UNCLASSIFIED')
crosswalk['updated_subsubtype'] = None

def clean_subtypes(row):
    subtype = row['subtype']
    if pd.isna(subtype):
        return 'UNCLASSIFIED'
    if row['type'] == 'HAZARD':
        if 'weather' in subtype.lower():
            return 'WEATHER'
        elif 'on_road' in subtype.lower():
            return 'ON ROAD'
        else:
            return 'UNCLASSIIFIED'
    return None

crosswalk['updated_subsubtype'] = crosswalk.apply(clean_subtypes, axis=1)
print(crosswalk)
```

c. Merge the crosswalk with the original data using type and subtype. How many rows are there for Accident - Unclassified?

There are 24,359 rows for Accident - Unclassified in the merged dataframe.

```{python}
full_waze_data['subtype'] = full_waze_data['subtype'].fillna('UNCLASSIFIED')

merged_waze = pd.merge(crosswalk, full_waze_data, how='right', on=['type', 'subtype'])
```

```{python}
print(len(merged_waze[(merged_waze['type'] == 'ACCIDENT') & (merged_waze['subtype'] == 'UNCLASSIFIED')]))
```

# App #1: Top Location by Alert Type Dashboard (30 points){-}
We will first make a spatial dashboard that displays the top 10 locations in Chicago with the highest number of alerts of a chosen type and subtype. Follow the lecture notes on how to create a Basic Shiny app and create it in a new folder called top_alerts_map (Note: remember to choose “No” when prompted to choose if you would like to use Shiny Express). Remember to use reactive decorators (e.g., @reactive_calc) to avoid unnecessary recalculations.

1. Let’s begin by by developing our output outside of Shiny. We will first clean and collapse the data.

a. The geo variable holds coordinates data, but they are stored in a string that represents the Well-Known Text representation of the point. Create two variables latitude and longitude after extracting the latitude and longitude from the string.

Hint: you will have to use regular expressions or regex to extract your text. You can look at the tutorial on regex here (here (link)) or prompt ChatGPT to put together a regular expression that extracts the coordinates. If you use ChatGPT, copy your prompt ChatGPT’s response below.

```{python}
pattern = r"POINT\((-?\d+\.\d+) (-?\d+\.\d+)\)" 

merged_waze[['Latitude', 'Longitude']] = merged_waze['geo'].str.extract(pattern)

merged_waze['Latitude'] = merged_waze['Latitude'].astype(float)
merged_waze['Longitude'] = merged_waze['Longitude'].astype(float)

print(merged_waze)
```

b. Bin the latitude and longitude variables into bins of step size 0.01. That is, coordinats with values of (-41.9232, -87.4251) should become (-41.92, -87.43). Which binned latitude-longitude combination has the greatest number of observations in the overall dataset?

```{python}
merged_waze['Latitude'] = (merged_waze['Latitude'] / 0.01).round() * 0.01
merged_waze['Longitude'] = (merged_waze['Longitude'] / 0.01).round() * 0.01

print(merged_waze[['Latitude', 'Longitude']])
```


c. Collapse the data down to the level of aggregation needed to plot the top 10 latitude-longitude bins with the highest number of alerts for a chosen type and subtype (Note: no sub-subtype). Save DataFrame as top_alerts_map.csv file in the top_alerts_map folder you created. What is the level of aggregation in this case? How many rows does this DataFrame have?

```{python}
top_alerts_map = merged_waze.groupby(['Latitude', 'Longitude', 'updated_type', 'updated_subtype']).size().reset_index(name='Alert_Count')

top_alerts = top_alerts_map.sort_values(by='Alert_Count').head(10)

print(top_alerts_map.sort_values(by='Alert_Count', ascending=False).head(10))
```

2. Using altair, plot a scatter plot where the x-axis is latitude and y-axis is longitude, and the points represent the latitude-longitude bins with the 10 highest number of “Jam- Heavy Traﬀic” alerts. Encode the size of the mark to represent the number of alerts. Hint: for a better presentation of the plot, you should set the domain of the x and y axis to be between some minimum and maximum values for the latitude and longitude.

```{python}
top_jam_alerts = top_alerts_map[(top_alerts_map['updated_type'] == 'JAM') & (top_alerts_map['updated_subtype'] == 'HEAVY TRAFFIC')]

chart = alt.Chart(top_jam_alerts).mark_circle(size=200).encode(
    x=alt.X('Latitude:Q', scale=alt.Scale(domain=[42, 43])),  
    y=alt.Y('Longitude:Q', scale=alt.Scale(domain=[-88, -87])),
    size='Alert_Count:Q', 
    tooltip=['Latitude', 'Longitude', 'Alert_Count']  #
).properties(
    title='Top Jam Alerts (Heavy Traffic)',
    width=300,  # Set the width of the chart
    height=200  
)

chart.show()
```

3. Next, we will layer the scatter plot on top of a map of Chicago.
    
a. Download the neighborhood boundaries as a GeoJSON from the Chicago Data Portal (link). EXTRA CREDIT: can you download the file directly with Python using the requests package?

```{python}

```
    

b. Load it into Python using the json package and prepare it for Altair using the following code:

```{python}
# MODIFY ACCORDINGLY
file_path = "./top_alerts_map/chicago-boundaries.geojson"
#----

with open(file_path) as f:
    chicago_geojson = json.load(f)

geo_data = alt.Data(values=chicago_geojson["features"])

```

For now on, follow the Altair documentation Altair geographic plots documentation (link) to plot geo_data in Altair. NOTE: Be particularly careful with your choice of the projection (project method) of the map. If you are having trouble with the map showing up correctly, you can try to use the equirectangular projection.

4. Layer the scatter plot from step 2 on top of a plot of the map using the information you loaded in step 3 and geo_data. Adjust the x and y axis domains so that the two layer correctly on top of each other. You may need to change the layering order of the map and the scatter plot or make the map fill transparent in order to properly see both plots.

```{python}

```

5. Now, we are ready to make our data and plot into the Shiny dashboard. In particular, we’re going to make a dashboard that lets users select in a single dropdown menu which combination of type and subtype they want to display. Once the user has made their selection, the app will show the 10 locations with the highest counts of those alerts.

a. For the UI component, create a single dropdown menu for type and subtype. Insert a screenshot of the dropdown menu below. How many total type x subtype combinations are there in your dropdown menu?

```{python}

```

b. Recreate the “Jam - Heavy Traﬀic” plot from above by using the dropdown menu and insert a screenshot of the graph below.

```{python}

```

c. Use your dashboard to answer the following question: where are alerts for road closures due to events most common? Insert a screenshot as your answer below.

```{python}

```

d. Other than the examples above, give an example of a question this dashboard could be used to answer. Formulate the question, take a screenshot of the selection and resulting plot in the dashboard, and then provide the answer.

```{python}

```

e. Can you suggest adding another column to the dashboard to enhance our analysis?

# App #2: Top Location by Alert Type and Hour Dashboard (20 points) {-}

1. We will now create a new App folder called top_alerts_map_byhour. This new app will modify your first app to add a slider to topalerts_map that lets users pick an hour of the day, and show the top 10 locations at that time of day. But, again, we will first work on the data outside of Shiny before we make the app.

a. Take a look at the whole dataset we are working with. Given the information present in the ts column, would you think that it would be a good idea to collapse the dataset by this column? Why or why not?


    
b. Create a new variable called hour that extracts the hour from the ts column (i.e. if the timestamp is 2024-01-01 01:34:32, the hour column should be 01:00). Then, generate a new collapsed dataset that has the required columns for us to plot the top 10 locations by hour, type and subtype (i.e. we want to add a new level of aggregation). How many rows does this dataset have? Beware that this might take some time to run. Save this collapsed dataset as top_alerts_map_byhour.csv in the top_alerts_map_byhour folder.

```{python}

```

c.Generate an individual plot of the top 10 locations by hour for ‘Jam - Heavy Traﬀic’ for three different times within a day. Don’t forget to use the map layer you created while working for the first app and use the same longitude and latitude ranges.

```{python}

```
    

2. We will now turn into creating the Shiny app. As mentioned, for this app we will have a single dropdown menu (similar to the one from App 1) and add a slider to pick the hour. Remember to not use the whole dataset for this app, but the collapsed dataset you created in the previous part.

a. Create the UI for the app, which should have the dropdown menu to choose a combination of type and subtype, and a slider to pick the hour. Insert a screenshot of the UI below.



b. Recreate the “Jam - Heavy Traﬀic” plot from above by using the dropdown menu and slider and insert a screenshot of each plot below.


c. Use your dashboard to answer the following question: does it seem like road construction is done more during morning hours or night hours? No need to insert more than two screenshots of the dashboard to support your answer.


# App #3: Top Location by Alert Type and Hour Dashboard (20 points){-}

1. As choosing a single hour might not the best way to look at this data, we will now create a new app that builds upon App 2. For this app, we will add a component that allows the user to pick a range of hours. For this new app, create a new folder called top_alerts_map_byhour_sliderrange. We will modify the app from the previous part to allow the user to go from a slider to a slider range – that is, it will allow the user to pick a range of hours like 6AM-10AM, rather than a single hour.


a. Think about what we did in App 1 and 2 regarding collapsing our dataset to make it easier for the Shiny app to handle the data. Given our goal of plotting the top 10 locations by alert type and range of hours, would it be a good idea to collapse the dataset by range of hours? Why or why not?

b. Before going into the Shiny app, create a plot of the top 10 locations by alert type and range of hours for Jam - Heavy Traﬀic between 6AM and 9AM.

```{python}

```

2. We will now create our new Shiny app adding the slider for the range of hours.

a. Create the required UI for the App, which should have the dropdown menu to choose a combination of type and subtype, and a slider to pick the hour range. Insert a screenshot of the UI below and the plot.


b. Recreate the “Jam - Heavy Traﬀic” plot from above by using the dropdown menu and slider range. Insert a screenshot of your App below
    
3. We will now add a conditional panel to the app to allow the user to toggle between the choice between a slide for a single hour or a slider for a range of hours. For this, we will use a switch button component.

a. Read the documentation on switch buttons and then add the switch button with the label “Toggle to switch to range of hours” to the app. Insert a screenshot of your App with the addition of the switch button (it doesn’t need to be functional yet) and answer the following question: what are the possible values (understood as the possible values for input.switch_button if the switch button is named switch_button) for this switch button?
    

b. Modify the UI to add a conditional panel that shows a slider for a single hour when the switch button is toggled. Insert two screenshots of your App with the addition of the conditional panel, demonstrating that when the switch button is toggled, the slider for a single hour is shown and when it is not toggled, the slider for a range
of hours is shown.


c. Lastly, modify the UI and server logic to add the functionality to the App so that when the switch button is toggled, the plot we show is the corresponding one according to our choice between hours (single hour or range of hours). Insert two screenshots showing this functionality: a plot generated with the slider for a single
hour and a plot generated with the slider for a range of hours using the conditional panel functionality.


d. EXTRA CREDIT: No need to code this part. What kind of changes would you make to the app in order for you to achieve a plot similar to the one below?
